{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f317d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca394bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes Genericas\n",
    "dataset = 'toldbr' # lacafe | fortuna | toldbr | offcombr\n",
    "\n",
    "# Constantes Lacafe\n",
    "if dataset == 'lacafe':\n",
    "    PATH = './Datasets/Lacafe' # Caminho para a pasta onde está o arquivo do dataset\n",
    "    ARCHIVE_NAME = 'df_dataset' # Nome do arquivo do dataset sem extensao\n",
    "    EXTENSION = 'csv' # Extensao do arquivo\n",
    "\n",
    "    TEXT_COLUMN = 'txt' # Nome da coluna no arquivo que representa o texto\n",
    "    CLASS_COLUMN = 'has_anger' # Nome da coluna no arquivo que representa a classe ou rotulo\n",
    "\n",
    "# Constantes Fortuna\n",
    "if dataset == 'fortuna':\n",
    "    PATH = './Datasets/Fortuna' # Caminho para a pasta onde está o arquivo do dataset\n",
    "    ARCHIVE_NAME = '2019-05-28_portuguese_hate_speech_binary_classification' # Nome do arquivo do dataset sem extensao\n",
    "    EXTENSION = 'csv' # Extensao do arquivo\n",
    "\n",
    "    TEXT_COLUMN = 'text' # Nome da coluna no arquivo que representa o texto\n",
    "    CLASS_COLUMN = 'hatespeech_comb' # Nome da coluna no arquivo que representa a classe ou rotulo\n",
    "\n",
    "# Constantes ToLD-BR\n",
    "if dataset == 'toldbr':\n",
    "    PATH = './Datasets/ToldBR' # Caminho para a pasta onde está o arquivo do dataset\n",
    "    ARCHIVE_NAME = 'ToLD-BR-Treated' # Nome do arquivo do dataset sem extensao\n",
    "    EXTENSION = 'csv' # Extensao do arquivo\n",
    "\n",
    "    TEXT_COLUMN = 'text' # Nome da coluna no arquivo que representa o texto\n",
    "    CLASS_COLUMN = 'hatespeech' # Nome da coluna no arquivo que representa a classe ou rotulo\n",
    "\n",
    "# Constantes OffComBr\n",
    "if dataset == 'offcombr':\n",
    "    PATH = './Datasets/OffComBR' # Caminho para a pasta onde está o arquivo do dataset\n",
    "    ARCHIVE_NAME = 'OffComBR2' # Nome do arquivo do dataset sem extensao\n",
    "    EXTENSION = 'csv' # Extensao do arquivo\n",
    "\n",
    "    TEXT_COLUMN = 'text' # Nome da coluna no arquivo que representa o texto\n",
    "    CLASS_COLUMN = 'offensive' # Nome da coluna no arquivo que representa a classe ou rotulo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514ed414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de dados: 21000\n",
      "Quantidade de classes positivas: 4063\n",
      "Quantidade de classes negativas: 16937\n",
      "\n",
      "Quantidade de exemplos: 8126\n",
      "\n",
      "Caminho do arquivo: ./Datasets/ToldBR/ToLD-BR-Treated_undersampling.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Executa a leitura do dataset base\n",
    "data = pd.read_csv(PATH + '/' + ARCHIVE_NAME + '.' + EXTENSION)\n",
    "\n",
    "if dataset == 'lacafe':\n",
    "    data = data[data['docno'] != 20410]\n",
    "\n",
    "# Descobre quandos exemplos de cada classe existem\n",
    "total_positive_examples = len(data[data[CLASS_COLUMN] == 1].values)\n",
    "total_negative_examples = len(data[data[CLASS_COLUMN] == 0].values)\n",
    "total = len(data.values)\n",
    "\n",
    "print('Total de dados: ' + str(total))\n",
    "print('Quantidade de classes positivas: ' + str(total_positive_examples))\n",
    "print('Quantidade de classes negativas: ' + str(total_negative_examples))\n",
    "print()\n",
    "\n",
    "# Pega os exemplos positivos e negativos separadamente e embaralha\n",
    "positive_examples = data[data[CLASS_COLUMN] == 1]\n",
    "negative_examples = data[data[CLASS_COLUMN] == 0]\n",
    "positive_examples = positive_examples.sample(frac=1)\n",
    "negative_examples = negative_examples.sample(frac=1)\n",
    "\n",
    "# Divide os datasets em dois (treino e teste)\n",
    "negative_examples = negative_examples.iloc[0:total_positive_examples]\n",
    "\n",
    "# Monta os datasets de treino e teste\n",
    "data = pd.concat([positive_examples, negative_examples])\n",
    "\n",
    "data = data[[TEXT_COLUMN, CLASS_COLUMN]]\n",
    "\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "print('Quantidade de exemplos: ' + str(len(data)))\n",
    "print()\n",
    "\n",
    "# Monta o caminho para salvar o arquivo\n",
    "path = f'{PATH}/{ARCHIVE_NAME}_undersampling.{EXTENSION}'\n",
    "\n",
    "print('Caminho do arquivo: ' + path)\n",
    "print()\n",
    "\n",
    "# Salva o arquivo de treino e teste\n",
    "if (not os.path.isfile(path)):\n",
    "    data.to_csv(path, encoding='utf-8', index=False)\n",
    "else:\n",
    "    raise Exception(f'Arquivo {path} já existe')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e5046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
